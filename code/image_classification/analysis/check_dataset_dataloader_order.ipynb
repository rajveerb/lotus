{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Subset\n",
    "from torch.profiler import profile, record_function, ProfilerActivity, schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir = os.path.join(\"/home/hice1/mrao70/scratch/special_problems/tiny-imagenet-200/\", \"train\")\n",
    "valdir = os.path.join(\"/home/hice1/mrao70/scratch/special_problems/tiny-imagenet-200/\", \"val\")\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ],\t\n",
    "    ),\n",
    ")\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    valdir,\n",
    "    transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ],\t\n",
    "    ),\n",
    ")\n",
    "\n",
    "# train_dataset = [(i, img) for i, img in enumerate(train_dataset)]\n",
    "# val_dataset = [(i, img) for i, img in enumerate(val_dataset)]\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    sampler=None,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    sampler=None,\n",
    ")\n",
    "\n",
    "# Check if the order of data in the dataloader is preserved\n",
    "\n",
    "# Enumerate over the data loader and print indices\n",
    "print(\"here\")\n",
    "for i, (index, data) in enumerate(train_loader):\n",
    "    print(f\"Batch {i} starts with index {index[0]}\")\n",
    "\n",
    "for i, (index, data) in enumerate(val_loader):\n",
    "    print(f\"Batch {i} starts with index {index[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
